{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8557e7b3",
      "metadata": {},
      "source": [
        "# Pandas + Seaborn Básico\n",
        "\n",
        "Notebook guiado para la clase de 3 horas.\n",
        "\n",
        "Objetivo: cargar, limpiar, agregar y visualizar datos de logs con `pandas` y `seaborn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e926eac",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
        "pd.set_option(\"display.max_columns\", 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52daddc4",
      "metadata": {},
      "source": [
        "## Setup rápido (ejecutar esto si saltas celdas)\n",
        "\n",
        "Carga `df` y `clean` para que las celdas avanzadas funcionen sin ejecutar todo el notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a156d363",
      "metadata": {},
      "source": [
        "## 1) Carga del dataset\n",
        "\n",
        "Múltiples fuentes: CSV, JSON y creación desde estructuras Python. Parámetros útiles de `read_csv`: `sep`, `encoding`, `parse_dates`, `na_values`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9182b8d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# CSV estándar\n",
        "df = pd.read_csv(\"data/titanic.csv\")\n",
        "\n",
        "# Ejemplo: crear DataFrame desde lista de dicts (como viene un JSON)\n",
        "# datos = [{\"a\": 1, \"b\": 2}, {\"a\": 3, \"b\": 4}]\n",
        "# df = pd.DataFrame(datos)\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "632996bd",
      "metadata": {},
      "source": [
        "## 2) Inspección profunda\n",
        "\n",
        "Validar estructura, tipos, duplicados, cardinalidad y patrones de nulos antes de analizar. Detectar problemas temprano evita errores posteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1021f0bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tipos y nulos\n",
        "print(\"=== info() ===\")\n",
        "df.info()\n",
        "\n",
        "# Estadísticas numéricas\n",
        "print(\"\\n=== describe() ===\")\n",
        "df.describe(include=\"all\").T.head(12)\n",
        "\n",
        "# Duplicados\n",
        "print(f\"\\n=== Duplicados: {df.duplicated().sum()} filas ===\")\n",
        "\n",
        "# Cardinalidad de columnas categóricas\n",
        "print(\"\\n=== Valores únicos por columna ===\")\n",
        "print(df.select_dtypes(include=[\"object\"]).nunique())\n",
        "\n",
        "# Patrón de nulos\n",
        "print(\"\\n=== Nulos por columna ===\")\n",
        "print(df.isna().sum().sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0353ef43",
      "metadata": {},
      "source": [
        "## 3) Visualización exploratoria en seaborn\n",
        "\n",
        "Múltiples gráficos para explorar relaciones: countplot, histplot, boxplot por categoría. Usar `order` para ordenar por frecuencia y `hue` para segmentar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "462c1063",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "ax = sns.countplot(data=df, x=\"Pclass\")\n",
        "ax.set_title(\"Pasajeros por clase\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d355d285",
      "metadata": {},
      "source": [
        "## 4) Selección y filtrado\n",
        "\n",
        "**`loc`**: acceso por etiquetas (nombres de índice y columnas). `iloc`: acceso por posición entera. Siempre usar `loc` para filtros por condición; `iloc` para slices numéricos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "480d2d3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# loc: por etiquetas (índice y nombres de columna)\n",
        "# df.loc[filas, columnas]\n",
        "df.loc[0, \"Name\"]                    # una celda\n",
        "df.loc[0:3, [\"Name\", \"Age\", \"Sex\"]]   # filas 0-3 (inclusivas), columnas especificadas\n",
        "\n",
        "# iloc: por posición entera (como en numpy)\n",
        "# df.iloc[fila_inicio:fila_fin, col_inicio:col_fin]\n",
        "df.iloc[0, 3]           # fila 0, columna 3 (Name)\n",
        "df.iloc[:5, :4]          # primeras 5 filas, primeras 4 columnas\n",
        "df.iloc[::2, 0]          # filas pares, columna 0\n",
        "\n",
        "# Diferencia clave: loc incluye el límite final, iloc no (como en Numpy)\n",
        "print(\"loc[0:2] incluye fila 2:\", df.loc[0:2, \"Name\"].index.tolist())\n",
        "print(\"iloc[0:2] NO incluye fila 2:\", df.iloc[0:2, 3].index.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a80c255",
      "metadata": {},
      "source": [
        "**Boolean indexing**: combinar condiciones con `&`, `|`, `~`. Siempre usar paréntesis alrededor de cada condición."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d59423d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejemplo 1: filtro compuesto con AND\n",
        "subset_df = df.loc[(df[\"Pclass\"] == 3) & (df[\"Fare\"] < 15), [\"Name\", \"Sex\", \"Age\", \"Fare\", \"Embarked\"]]\n",
        "print(f\"Pasajeros en 3a clase con tarifa < 15: {len(subset_df)}\")\n",
        "subset_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98c20f02",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejemplo 2: filtro con OR\n",
        "women_or_first_class = df.loc[(df[\"Sex\"] == \"female\") | (df[\"Pclass\"] == 1)]\n",
        "print(f\"Mujeres O primera clase: {len(women_or_first_class)}\")\n",
        "\n",
        "# Ejemplo 3: filtro con NOT (~)\n",
        "not_survived = df.loc[~(df[\"Survived\"] == 1)]\n",
        "print(f\"No sobrevivientes: {len(not_survived)}\")\n",
        "\n",
        "# Ejemplo 4: isin para múltiples valores\n",
        "embarked_sc = df.loc[df[\"Embarked\"].isin([\"S\", \"C\"])]\n",
        "print(f\"Embarcados en S o C: {len(embarked_sc)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "880c7125",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejemplo 5: between para rangos\n",
        "adults_young = df.loc[df[\"Age\"].between(18, 35)]\n",
        "print(f\"Adultos jovenes (18-35): {len(adults_young)}\")\n",
        "\n",
        "# Ejemplo 6: query - sintaxis más limpia\n",
        "queried = df.query(\"Pclass == 1 and Survived == 1 and Sex == 'female'\")\n",
        "print(f\"Mujeres supervivientes de 1a clase: {len(queried)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2acca64c",
      "metadata": {},
      "source": [
        "## 5) Limpieza básica de tipos y nulos\n",
        "\n",
        "Titanic ya viene con nulos reales, ideal para practicar limpieza. Age y Cabin tienen valores faltantes que debemos tratar antes de analizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "985dd67b",
      "metadata": {},
      "outputs": [],
      "source": [
        "clean = df.copy()\n",
        "\n",
        "clean[\"Age\"] = pd.to_numeric(clean[\"Age\"], errors=\"coerce\")\n",
        "clean[\"Fare\"] = pd.to_numeric(clean[\"Fare\"], errors=\"coerce\")\n",
        "clean[\"Embarked\"] = clean[\"Embarked\"].fillna(clean[\"Embarked\"].mode()[0])\n",
        "clean[\"Age\"] = clean[\"Age\"].fillna(clean[\"Age\"].median())\n",
        "\n",
        "print(clean.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29a37d46",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "sns.heatmap(df.isna(), cbar=False, cmap=\"viridis\")\n",
        "plt.title(\"Mapa de nulos en titanic (amarillo = nulo)\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "546371c7",
      "metadata": {},
      "source": [
        "## 6) Agregacion y visualizacion\n",
        "\n",
        "Resumimos por clase y sexo, y vemos supervivencia por edad. Groupby es una de las operaciones más potentes de pandas para análisis exploratorio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3919459f",
      "metadata": {},
      "outputs": [],
      "source": [
        "agg_survival = (\n",
        "    clean.groupby([\"Pclass\", \"Sex\"], as_index=False)\n",
        "         .agg(passengers=(\"PassengerId\", \"count\"), survival_rate=(\"Survived\", \"mean\"))\n",
        "         .sort_values([\"Pclass\", \"Sex\"])\n",
        ")\n",
        "agg_survival.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3867b5e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(data=agg_survival, x=\"Pclass\", y=\"survival_rate\", hue=\"Sex\")\n",
        "plt.title(\"Tasa de supervivencia por clase y sexo\")\n",
        "plt.ylim(0, 1)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9177d90",
      "metadata": {},
      "outputs": [],
      "source": [
        "age_curve = (\n",
        "    clean.assign(age_bin=(clean[\"Age\"] // 10) * 10)\n",
        "         .groupby(\"age_bin\", as_index=False)\n",
        "         .agg(survival_rate=(\"Survived\", \"mean\"))\n",
        "         .sort_values(\"age_bin\")\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.lineplot(data=age_curve, x=\"age_bin\", y=\"survival_rate\", marker=\"o\")\n",
        "plt.title(\"Tasa de supervivencia por rango de edad\")\n",
        "plt.xlabel(\"Rango de edad (inicio)\")\n",
        "plt.ylabel(\"Tasa de supervivencia\")\n",
        "plt.ylim(0, 1)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "060447fa",
      "metadata": {},
      "source": [
        "## 7) Series vs DataFrame\n",
        "\n",
        "Una Serie es una columna con indice. Un DataFrame es una coleccion de Series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71775ace",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Serie: una columna\n",
        "ages = clean[\"Age\"]\n",
        "print(type(ages), ages.shape)\n",
        "\n",
        "# DataFrame: varias columnas\n",
        "subset = clean[[\"Name\", \"Age\", \"Sex\"]]\n",
        "print(type(subset), subset.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ebf92fd",
      "metadata": {},
      "source": [
        "## 8) Index como ciudadano de primera clase\n",
        "\n",
        "El indice no es solo decoracion: acelera lookups y facilita joins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e14d86b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Usar PassengerId como indice\n",
        "indexed = clean.set_index(\"PassengerId\")\n",
        "indexed.head(3)\n",
        "\n",
        "# Lookup rápido por indice\n",
        "indexed.loc[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66f82bd8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# MultiIndex: indices jerárquicos\n",
        "multi_idx = clean.set_index([\"Pclass\", \"Sex\"])\n",
        "multi_idx.head()\n",
        "\n",
        "# Filtrar por nivel de indice\n",
        "multi_idx.loc[(3, \"male\")].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b88eac6c",
      "metadata": {},
      "source": [
        "## 9) Groupby avanzado: agg, transform, apply\n",
        "\n",
        "`agg` resume, `transform` mantiene forma original, `apply` es flexible pero lento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3e39a69",
      "metadata": {},
      "outputs": [],
      "source": [
        "# agg: resume\n",
        "clean.groupby(\"Pclass\").agg({\"Age\": [\"mean\", \"std\"], \"Fare\": \"median\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b42ab6c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# transform: devuelve serie del mismo tamaño que el df original\n",
        "clean[\"age_vs_class_mean\"] = clean.groupby(\"Pclass\")[\"Age\"].transform(\"mean\")\n",
        "clean[[\"PassengerId\", \"Pclass\", \"Age\", \"age_vs_class_mean\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06362590",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agregacion con nombres custom (más legible)\n",
        "clean.groupby(\"Pclass\").agg(\n",
        "    edad_promedio=(\"Age\", \"mean\"),\n",
        "    edad_std=(\"Age\", \"std\"),\n",
        "    tarifa_mediana=(\"Fare\", \"median\"),\n",
        "    pasajeros=(\"PassengerId\", \"count\")\n",
        ").round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "733e614c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# apply: flexible pero lento - usar solo si no hay alternativa vectorizada\n",
        "def custom_func(group):\n",
        "    return group[\"Age\"].max() - group[\"Age\"].min()\n",
        "\n",
        "clean.groupby(\"Pclass\").apply(custom_func, include_groups=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c2e5de",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diferencia clave: agg reduce, transform mantiene forma\n",
        "print(\"Forma original:\", clean.shape)\n",
        "print(\"Forma despues de agg:\", clean.groupby(\"Pclass\").agg({\"Age\": \"mean\"}).shape)\n",
        "\n",
        "# Con transform obtenemos una columna del tamano original\n",
        "clean[\"age_diff_vs_class\"] = clean[\"Age\"] - clean.groupby(\"Pclass\")[\"Age\"].transform(\"mean\")\n",
        "clean[[\"PassengerId\", \"Pclass\", \"Age\", \"age_vs_class_mean\", \"age_diff_vs_class\"]].head(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c46a69",
      "metadata": {},
      "source": [
        "## 10) Merge / Join\n",
        "\n",
        "Combinar dataframes por columna o indice. Senior entiende left/right/inner/outer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f34f799",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear tabla auxiliar de precios de clase\n",
        "prices = pd.DataFrame({\"Pclass\": [1, 2, 3], \"base_price\": [100, 50, 20]})\n",
        "\n",
        "# Left join: mantiene todas las filas del df principal\n",
        "merged = pd.merge(clean.head(10), prices, on=\"Pclass\", how=\"left\")\n",
        "merged[[\"PassengerId\", \"Pclass\", \"Fare\", \"base_price\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb15afdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Join por indice (alternativa a merge)\n",
        "df1 = clean.set_index(\"PassengerId\")[[\"Name\", \"Sex\"]].head(5)\n",
        "df2 = clean.set_index(\"PassengerId\")[[\"Age\", \"Fare\"]].head(7)\n",
        "\n",
        "df1.join(df2, how=\"inner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9888bce7",
      "metadata": {},
      "source": [
        "## 11) Performance: evitar loops\n",
        "\n",
        "Nunca iterar fila por fila. Usar operaciones vectorizadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec9c2ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparar diferentes tipos de joins\n",
        "df_left = clean[[\"PassengerId\", \"Name\", \"Pclass\"]].head(5)\n",
        "df_right = clean[[\"PassengerId\", \"Age\", \"Fare\"]].iloc[3:8]\n",
        "\n",
        "print(\"Left tiene:\", len(df_left), \"filas\")\n",
        "print(\"Right tiene:\", len(df_right), \"filas\")\n",
        "\n",
        "# Inner: solo coincidencias\n",
        "inner = pd.merge(df_left, df_right, on=\"PassengerId\", how=\"inner\")\n",
        "print(f\"\\nInner join: {len(inner)} filas (solo PassengerId en ambos)\")\n",
        "\n",
        "# Left: mantiene todas de la izquierda\n",
        "left = pd.merge(df_left, df_right, on=\"PassengerId\", how=\"left\")\n",
        "print(f\"Left join: {len(left)} filas (todas las de df_left)\")\n",
        "\n",
        "# Outer: union de ambas\n",
        "outer = pd.merge(df_left, df_right, on=\"PassengerId\", how=\"outer\")\n",
        "print(f\"Outer join: {len(outer)} filas (union completa)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1967961e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAL: loop\n",
        "# for i, row in clean.iterrows():\n",
        "#     clean.at[i, \"adult\"] = 1 if row[\"Age\"] >= 18 else 0\n",
        "\n",
        "# BIEN: vectorizacion\n",
        "clean[\"adult\"] = (clean[\"Age\"] >= 18).astype(int)\n",
        "clean[[\"Age\", \"adult\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18ec2282",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# MAL Lento: apply\n",
        "# clean[\"fare_category\"] = clean[\"Fare\"].apply(lambda x: \"high\" if x > 30 else \"low\")\n",
        "\n",
        "# BIEN Rapido: np.where\n",
        "clean[\"fare_category\"] = np.where(clean[\"Fare\"] > 30, \"high\", \"low\")\n",
        "clean[[\"Fare\", \"fare_category\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10c99ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Comparacion de rendimiento: loop vs vectorizacion\n",
        "df_test = clean.copy()\n",
        "\n",
        "# Opcion 1: loop (LENTO)\n",
        "start = time.time()\n",
        "result_loop = []\n",
        "for idx, row in df_test.head(1000).iterrows():\n",
        "    result_loop.append(1 if row[\"Age\"] >= 18 else 0)\n",
        "time_loop = time.time() - start\n",
        "\n",
        "# Opcion 2: vectorizacion (RAPIDO)\n",
        "start = time.time()\n",
        "result_vec = (df_test.head(1000)[\"Age\"] >= 18).astype(int)\n",
        "time_vec = time.time() - start\n",
        "\n",
        "print(f\"Loop: {time_loop*1000:.2f}ms\")\n",
        "print(f\"Vectorizacion: {time_vec*1000:.2f}ms\")\n",
        "print(f\"Speedup: {time_loop/time_vec:.0f}x más rápido\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee21eed",
      "metadata": {},
      "outputs": [],
      "source": [
        "# np.select para condiciones múltiples (más legible que np.where anidado)\n",
        "conditions = [\n",
        "    clean[\"Fare\"] > 50,\n",
        "    clean[\"Fare\"] > 20,\n",
        "    clean[\"Fare\"] > 0\n",
        "]\n",
        "choices = [\"premium\", \"medium\", \"low\"]\n",
        "clean[\"fare_tier\"] = np.select(conditions, choices, default=\"unknown\")\n",
        "\n",
        "clean[[\"Fare\", \"fare_tier\"]].value_counts(\"fare_tier\").sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62cb58be",
      "metadata": {},
      "source": [
        "## 12) Optimizar dtypes para reducir memoria\n",
        "\n",
        "Convertir object a category, float64 a float32 cuando sea posible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c5a80e",
      "metadata": {},
      "outputs": [],
      "source": [
        "mem_before = clean.memory_usage(deep=True).sum() / 1024**2\n",
        "\n",
        "# Convertir columnas categoricas a dtype category\n",
        "clean[\"Sex\"] = clean[\"Sex\"].astype(\"category\")\n",
        "clean[\"Embarked\"] = clean[\"Embarked\"].astype(\"category\")\n",
        "\n",
        "mem_after = clean.memory_usage(deep=True).sum() / 1024**2\n",
        "print(f\"Memoria antes: {mem_before:.2f} MB\")\n",
        "print(f\"Memoria despues: {mem_after:.2f} MB\")\n",
        "print(f\"Reduccion: {(1 - mem_after/mem_before)*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3cc8a1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimizar numericos: float64 -> float32 (cuidado con precision)\n",
        "clean[\"Fare_f32\"] = clean[\"Fare\"].astype(\"float32\")\n",
        "print(\"Memoria Fare float64:\", clean[\"Fare\"].memory_usage(deep=True) / 1024, \"KB\")\n",
        "print(\"Memoria Fare float32:\", clean[\"Fare_f32\"].memory_usage(deep=True) / 1024, \"KB\")\n",
        "\n",
        "# Mostrar todos los dtypes actuales\n",
        "print(\"\\nDtypes del dataframe:\")\n",
        "clean.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4d6ecc4",
      "metadata": {},
      "source": [
        "## 13) Copy vs View (SettingWithCopyWarning)\n",
        "\n",
        "Evitar modificar vistas implícitas. Usar `.copy()` explícito o `.loc`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f5b62f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAL TRAMPA: puede generar SettingWithCopyWarning\n",
        "# subset = clean[clean[\"Pclass\"] == 3]\n",
        "# subset[\"new_col\"] = 1  # warning!\n",
        "\n",
        "# BIEN SOLUCION 1: copy explícito\n",
        "subset = clean[clean[\"Pclass\"] == 3].copy()\n",
        "subset[\"new_col\"] = 1\n",
        "\n",
        "# BIEN SOLUCION 2: usar loc desde el inicio\n",
        "clean.loc[clean[\"Pclass\"] == 3, \"new_col\"] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ea58715",
      "metadata": {},
      "source": [
        "## 14) Limpieza avanzada: strings\n",
        "\n",
        "Metodos `.str` para normalizar texto. Los accessors de string permiten aplicar operaciones de texto de forma vectorizada sobre columnas completas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7678e69e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extraer informacion de strings con regex\n",
        "clean[\"Title\"] = clean[\"Name\"].str.extract(r',\\s*([^\\.]+)\\.', expand=False)\n",
        "print(\"Titulos unicos encontrados:\")\n",
        "print(clean[\"Title\"].value_counts().head(10))\n",
        "\n",
        "# Reemplazar y normalizar\n",
        "clean[\"Title_clean\"] = clean[\"Title\"].str.strip().str.replace(\"Mlle\", \"Miss\").str.replace(\"Ms\", \"Miss\")\n",
        "clean[[\"Name\", \"Title\", \"Title_clean\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d112eaa9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizar nombres: lowercase, strip, extrae titulo\n",
        "clean[\"name_clean\"] = clean[\"Name\"].str.lower().str.strip()\n",
        "clean[\"has_mr\"] = clean[\"Name\"].str.contains(\"Mr.\", na=False).astype(int)\n",
        "\n",
        "clean[[\"Name\", \"name_clean\", \"has_mr\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bad80875",
      "metadata": {},
      "source": [
        "## 15) Pipelines reproducibles: method chaining\n",
        "\n",
        "Encadenar operaciones sin variables intermedias. Más legible y reproducible. Este estilo facilita debug y mantiene el código limpio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a041d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "result = (\n",
        "    clean\n",
        "    .query(\"Pclass == 3 and Age > 18\")\n",
        "    .assign(fare_per_year=lambda x: x[\"Fare\"] / x[\"Age\"])\n",
        "    .groupby(\"Sex\", as_index=False)\n",
        "    .agg(count=(\"PassengerId\", \"count\"), avg_fare_per_year=(\"fare_per_year\", \"mean\"))\n",
        "    .sort_values(\"avg_fare_per_year\", ascending=False)\n",
        ")\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42942a0b",
      "metadata": {},
      "source": [
        "## 18) Pivot table y reshape\n",
        "\n",
        "Reorganizar datos: pivot_table para resumir, melt para formato largo. Estas transformaciones son fundamentales para preparar datos para visualizacion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ca1daa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pivot table: tabla resumen con indices y columnas\n",
        "pivot = clean.pivot_table(\n",
        "    values=\"Survived\",\n",
        "    index=\"Pclass\",\n",
        "    columns=\"Sex\",\n",
        "    aggfunc=\"mean\"\n",
        ")\n",
        "print(\"Tasa de supervivencia por clase y sexo:\")\n",
        "pivot.round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b14eddcc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Melt: formato ancho -> largo (util para visualizacion)\n",
        "sample_wide = clean[[\"PassengerId\", \"Age\", \"Fare\"]].head(3)\n",
        "print(\"Formato ancho (wide):\")\n",
        "print(sample_wide)\n",
        "\n",
        "sample_long = sample_wide.melt(id_vars=\"PassengerId\", var_name=\"metric\", value_name=\"value\")\n",
        "print(\"\\nFormato largo (long) - mejor para seaborn:\")\n",
        "print(sample_long)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afa5069f",
      "metadata": {},
      "source": [
        "## 19) Manejo de fechas y tiempo\n",
        "\n",
        "Datetime es crucial en análisis real. Pandas tiene herramientas potentes para fechas: parsing, extraccion de componentes, operaciones aritméticas y resampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3592fbbb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear data con fechas simuladas\n",
        "clean_dates = clean.head(100).copy()\n",
        "clean_dates[\"boarding_date\"] = pd.date_range(start=\"1912-04-10\", periods=100, freq=\"h\")\n",
        "\n",
        "# Extraer componentes de fecha\n",
        "clean_dates[\"year\"] = clean_dates[\"boarding_date\"].dt.year\n",
        "clean_dates[\"month\"] = clean_dates[\"boarding_date\"].dt.month\n",
        "clean_dates[\"day\"] = clean_dates[\"boarding_date\"].dt.day\n",
        "clean_dates[\"hour\"] = clean_dates[\"boarding_date\"].dt.hour\n",
        "clean_dates[\"day_name\"] = clean_dates[\"boarding_date\"].dt.day_name()\n",
        "\n",
        "clean_dates[[\"PassengerId\", \"boarding_date\", \"year\", \"month\", \"day\", \"hour\", \"day_name\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e751caf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Operaciones con fechas\n",
        "clean_dates[\"days_since_start\"] = (clean_dates[\"boarding_date\"] - clean_dates[\"boarding_date\"].min()).dt.days\n",
        "clean_dates[\"in_weekend\"] = clean_dates[\"boarding_date\"].dt.dayofweek >= 5\n",
        "\n",
        "# Resample: agrupar por ventana temporal\n",
        "time_agg = (\n",
        "    clean_dates.set_index(\"boarding_date\")\n",
        "    .resample(\"6h\")[\"Survived\"]\n",
        "    .agg([\"count\", \"mean\"])\n",
        ")\n",
        "print(\"Agregacion por ventanas de 6 horas:\")\n",
        "time_agg.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2acd5958",
      "metadata": {},
      "source": [
        "## 20) Validacion y testing de datos\n",
        "\n",
        "Validar suposiciones y detectar anomalias antes de analizar. Las assertions ayudan a detectar problemás temprano y documentan expectativas sobre los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "038a2ad2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assertions básicas para validar datos\n",
        "assert clean.shape[0] > 0, \"Dataset vacio!\"\n",
        "assert clean[\"Age\"].min() >= 0, \"Edad negativa detectada\"\n",
        "assert clean[\"Pclass\"].isin([1, 2, 3]).all(), \"Clase invalida\"\n",
        "print(\"OK Validaciones básicas pasadas\")\n",
        "\n",
        "# Detectar duplicados\n",
        "print(f\"Filas duplicadas: {clean.duplicated().sum()}\")\n",
        "print(f\"PassengerId duplicados: {clean['PassengerId'].duplicated().sum()}\")\n",
        "\n",
        "# Detectar outliers (metodo IQR)\n",
        "Q1 = clean[\"Fare\"].quantile(0.25)\n",
        "Q3 = clean[\"Fare\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers = clean[(clean[\"Fare\"] < Q1 - 1.5*IQR) | (clean[\"Fare\"] > Q3 + 1.5*IQR)]\n",
        "print(f\"Outliers detectados en Fare: {len(outliers)} ({len(outliers)/len(clean)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9e18573",
      "metadata": {},
      "source": [
        "## 22) Visualizaciones avanzadas con seaborn\n",
        "\n",
        "Graficos más complejos para comunicar insights. Boxplots, violinplots, heatmaps y pairplots son herramientas clave para análisis exploratorio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4875f9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Boxplot: detectar outliers y distribucion\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=clean, x=\"Pclass\", y=\"Fare\", hue=\"Survived\")\n",
        "plt.title(\"Distribucion de tarifa por clase y supervivencia\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Violin plot: distribucion + densidad\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.violinplot(data=clean, x=\"Pclass\", y=\"Age\", hue=\"Survived\", split=True)\n",
        "plt.title(\"Distribucion de edad por clase (split por supervivencia)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75d92f35",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Heatmap de correlaciones\n",
        "plt.figure(figsize=(8, 6))\n",
        "corr_matrix = clean[[\"Survived\", \"Pclass\", \"Age\", \"Fare\"]].corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", center=0, fmt=\".2f\")\n",
        "plt.title(\"Matriz de correlación\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Pairplot: relaciones múltiples\n",
        "sample_for_pair = clean[[\"Survived\", \"Pclass\", \"Age\", \"Fare\"]].dropna().sample(200, random_state=42)\n",
        "sns.pairplot(sample_for_pair, hue=\"Survived\", diag_kind=\"kde\", corner=True)\n",
        "plt.suptitle(\"Pairplot de variables principales\", y=1.01)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2534b431",
      "metadata": {},
      "source": [
        "## 16) IO serio: parquet y chunking\n",
        "\n",
        "Parquet es más eficiente que CSV. Chunking para datasets grandes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658bd7fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar y leer en parquet (más rápido y compacto que CSV)\n",
        "clean.to_parquet(\"data/titanic.parquet\", index=False)\n",
        "df_parquet = pd.read_parquet(\"data/titanic.parquet\")\n",
        "df_parquet.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65459978",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chunking: procesar datasets grandes por bloques\n",
        "chunk_results = []\n",
        "for chunk in pd.read_csv(\"data/titanic.csv\", chunksize=100):\n",
        "    # Procesar cada chunk\n",
        "    chunk_agg = chunk.groupby(\"Pclass\")[\"Survived\"].mean()\n",
        "    chunk_results.append(chunk_agg)\n",
        "\n",
        "# Combinar resultados\n",
        "final = pd.concat(chunk_results, axis=1).mean(axis=1)\n",
        "print(\"Supervivencia promedio por clase (via chunks):\")\n",
        "print(final)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbe79b7f",
      "metadata": {},
      "source": [
        "## 17) Cuando NO usar pandas\n",
        "\n",
        "Senior sabe cuando pandas NO es la herramienta correcta."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "331f36f4",
      "metadata": {},
      "source": [
        "Pandas NO es ideal para:\n",
        "\n",
        "- **Datasets > 10GB en RAM**: considerar Dask, Polars, PySpark.\n",
        "- **Joins masivos repetidos**: bases de datos SQL son más eficientes.\n",
        "- **Procesamiento distribuido**: Spark, Dask distributed.\n",
        "- **Alta concurrencia**: pandas no es thread-safe.\n",
        "\n",
        "Alternativas:\n",
        "- `polars`: más rápido, mejor memoria.\n",
        "- `dask`: pandas distribuido.\n",
        "- `pyspark`: big data distribuido."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcd0de51",
      "metadata": {},
      "source": [
        "## 23) Troubleshooting y errores comunes\n",
        "\n",
        "Soluciones rápidas a problemás frecuentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cfb1bbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Error comun 1: KeyError\n",
        "try:\n",
        "    valor = clean[\"columna_inexistente\"]\n",
        "except KeyError as e:\n",
        "    print(f\"ERROR KeyError: {e}\")\n",
        "    print(\"Solucion: verificar con clean.columns\")\n",
        "\n",
        "# Error comun 2: ValueError en merge por tipos incompatibles\n",
        "# Asegurar que las columnas de join tengan el mismo dtype\n",
        "\n",
        "# Error comun 3: MemoryError\n",
        "# Solucion: usar chunking, optimizar dtypes, o cambiar a Dask/Polars\n",
        "\n",
        "# Error comun 4: AttributeError 'Series' object has no attribute 'columns'\n",
        "# Solucion: verificar si es Series (1D) o DataFrame (2D)\n",
        "print(f\"Type: {type(clean['Age'])} -> usa .shape, no .columns\")\n",
        "print(f\"Type: {type(clean[['Age']])} -> tiene .columns\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
